{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 12: Classification with topic modelling features (using BoW and LDA).\n",
    "\n",
    "In this notebook we are going to perform classification on a text dataset using features from topic modelling. There is a similiar notebook to this that just uses Bag of Words as the text feature for classification. \n",
    "\n",
    "This notebook uses the [Myers-Briggs comments dataset](../data/myers_briggs_comments.tsv) that is scraped from the website [16personalities.com](https://www.16personalities.com/) using web-scraping code by Terence Broad. The [Myers-Briggs personality typology](https://en.wikipedia.org/wiki/Myers%E2%80%93Briggs_Type_Indicator) is a categorisation for personality types that result from a questionnaire that asks people how they make decision and percieve the world. The questionnaire breaks people down into 16 personality types, made up of four binary categories:\n",
    "\n",
    "![Myers-Briggs personality types](../media/MyersBriggsTypes.png)\n",
    "\n",
    "The website 16 personalities offers these questionairres, while also giving information about each personality type. On this website people can make accounts, and when they have done the test, their personality type appears on their user profile. Each page has a comments section and this dataset is made from exhuastively scraping all of these comments, along with their associated personality type. In addition to the 16 personalities, the website goes further to add the `-T` and `-A` types (being 'Turbulent' and 'Assertive'), meaning they actual end up tracking 32 personality types (2 to the power 5). These personality types is something we will learn about in more detail in Personalisation and Machine Learning in Term 3.\n",
    "\n",
    "We are going to use this dataset to do some classification, looking at the many different ways we can split this dataset to see which factors of personality are most easily predicted based on. Then we will look at different ways we might try and improve our accuracy with classification.\n",
    "\n",
    "First lets do some imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "# NLTK utils\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Bag of words and LDA \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Classification stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And download these if we haven't already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/arnoldm./nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/arnoldm./nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/arnoldm./nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Util function for part of speech tagging for lemmatisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function originally from: https://www.programcreek.com/python/?CodeExample=get%20wordnet%20pos\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets load and look at our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>personality type</th>\n",
       "      <th>source url</th>\n",
       "      <th>comment</th>\n",
       "      <th>is_reply</th>\n",
       "      <th>parent_comment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77016</td>\n",
       "      <td>INFP-A</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>Hello friends infp, I identify a lot with all ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77025</td>\n",
       "      <td>ISTP-T</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>I can't believe how accurate this was, it's so...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77700</td>\n",
       "      <td>INFP-T</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>We matter. I am Grace too.  It is so refreshin...</td>\n",
       "      <td>True</td>\n",
       "      <td>77073.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77073</td>\n",
       "      <td>INFP-T</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>Finally I know for sure that I am not a weirdo...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77151</td>\n",
       "      <td>INFP-T</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>I finally feel understood. I always give and g...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41695</th>\n",
       "      <td>119246</td>\n",
       "      <td>ENTP-T</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>I'm such a debater I had to debate before deci...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41696</th>\n",
       "      <td>119900</td>\n",
       "      <td>ENTP-A</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>Accurate</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697</th>\n",
       "      <td>121460</td>\n",
       "      <td>ENTP-A</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>Debatable</td>\n",
       "      <td>True</td>\n",
       "      <td>119995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41698</th>\n",
       "      <td>120098</td>\n",
       "      <td>ENTP-T</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>relatable</td>\n",
       "      <td>True</td>\n",
       "      <td>119995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41699</th>\n",
       "      <td>119995</td>\n",
       "      <td>ENTP-T</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>I debated the actuality of being being a debat...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41700 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       comment_id personality type  \\\n",
       "0           77016           INFP-A   \n",
       "1           77025           ISTP-T   \n",
       "2           77700           INFP-T   \n",
       "3           77073           INFP-T   \n",
       "4           77151           INFP-T   \n",
       "...           ...              ...   \n",
       "41695      119246           ENTP-T   \n",
       "41696      119900           ENTP-A   \n",
       "41697      121460           ENTP-A   \n",
       "41698      120098           ENTP-T   \n",
       "41699      119995           ENTP-T   \n",
       "\n",
       "                                              source url  \\\n",
       "0      https://www.16personalities.com/infp-strengths...   \n",
       "1      https://www.16personalities.com/infp-strengths...   \n",
       "2      https://www.16personalities.com/infp-strengths...   \n",
       "3      https://www.16personalities.com/infp-strengths...   \n",
       "4      https://www.16personalities.com/infp-strengths...   \n",
       "...                                                  ...   \n",
       "41695   https://www.16personalities.com/entp-personality   \n",
       "41696   https://www.16personalities.com/entp-personality   \n",
       "41697   https://www.16personalities.com/entp-personality   \n",
       "41698   https://www.16personalities.com/entp-personality   \n",
       "41699   https://www.16personalities.com/entp-personality   \n",
       "\n",
       "                                                 comment  is_reply  \\\n",
       "0      Hello friends infp, I identify a lot with all ...     False   \n",
       "1      I can't believe how accurate this was, it's so...     False   \n",
       "2      We matter. I am Grace too.  It is so refreshin...      True   \n",
       "3      Finally I know for sure that I am not a weirdo...     False   \n",
       "4      I finally feel understood. I always give and g...     False   \n",
       "...                                                  ...       ...   \n",
       "41695  I'm such a debater I had to debate before deci...     False   \n",
       "41696                                           Accurate     False   \n",
       "41697                                          Debatable      True   \n",
       "41698                                          relatable      True   \n",
       "41699  I debated the actuality of being being a debat...     False   \n",
       "\n",
       "       parent_comment_id  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                77073.0  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "...                  ...  \n",
       "41695                NaN  \n",
       "41696                NaN  \n",
       "41697           119995.0  \n",
       "41698           119995.0  \n",
       "41699                NaN  \n",
       "\n",
       "[41700 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/myers_briggs_comments.tsv', sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can delete the columns `comment_id` and `parent_comment_id` (we aren't going to use the columns `source url` and `is_reply`, but they may come in handy in the bonus tasks later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personality type</th>\n",
       "      <th>source url</th>\n",
       "      <th>comment</th>\n",
       "      <th>is_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFP-A</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>Hello friends infp, I identify a lot with all ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISTP-T</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>I can't believe how accurate this was, it's so...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFP-T</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>We matter. I am Grace too.  It is so refreshin...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFP-T</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>Finally I know for sure that I am not a weirdo...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFP-T</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>I finally feel understood. I always give and g...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41695</th>\n",
       "      <td>ENTP-T</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>I'm such a debater I had to debate before deci...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41696</th>\n",
       "      <td>ENTP-A</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>Accurate</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697</th>\n",
       "      <td>ENTP-A</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>Debatable</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41698</th>\n",
       "      <td>ENTP-T</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>relatable</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41699</th>\n",
       "      <td>ENTP-T</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>I debated the actuality of being being a debat...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41700 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      personality type                                         source url  \\\n",
       "0               INFP-A  https://www.16personalities.com/infp-strengths...   \n",
       "1               ISTP-T  https://www.16personalities.com/infp-strengths...   \n",
       "2               INFP-T  https://www.16personalities.com/infp-strengths...   \n",
       "3               INFP-T  https://www.16personalities.com/infp-strengths...   \n",
       "4               INFP-T  https://www.16personalities.com/infp-strengths...   \n",
       "...                ...                                                ...   \n",
       "41695           ENTP-T   https://www.16personalities.com/entp-personality   \n",
       "41696           ENTP-A   https://www.16personalities.com/entp-personality   \n",
       "41697           ENTP-A   https://www.16personalities.com/entp-personality   \n",
       "41698           ENTP-T   https://www.16personalities.com/entp-personality   \n",
       "41699           ENTP-T   https://www.16personalities.com/entp-personality   \n",
       "\n",
       "                                                 comment  is_reply  \n",
       "0      Hello friends infp, I identify a lot with all ...     False  \n",
       "1      I can't believe how accurate this was, it's so...     False  \n",
       "2      We matter. I am Grace too.  It is so refreshin...      True  \n",
       "3      Finally I know for sure that I am not a weirdo...     False  \n",
       "4      I finally feel understood. I always give and g...     False  \n",
       "...                                                  ...       ...  \n",
       "41695  I'm such a debater I had to debate before deci...     False  \n",
       "41696                                           Accurate     False  \n",
       "41697                                          Debatable      True  \n",
       "41698                                          relatable      True  \n",
       "41699  I debated the actuality of being being a debat...     False  \n",
       "\n",
       "[41700 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('comment_id', axis=1)\n",
    "df = df.drop('parent_comment_id', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatizer\n",
    "\n",
    "Now lets run our lemmatizer on the comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/arnoldm./nltk_data', '/Users/arnoldm./NLP/venv/nltk_data', '/Users/arnoldm./NLP/venv/share/nltk_data', '/Users/arnoldm./NLP/venv/lib/nltk_data', '/usr/share/nltk_data', '/usr/local/share/nltk_data', '/usr/lib/nltk_data', '/usr/local/lib/nltk_data']\n"
     ]
    }
   ],
   "source": [
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/arnoldm./nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personality type</th>\n",
       "      <th>source url</th>\n",
       "      <th>comment</th>\n",
       "      <th>is_reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFP-A</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>Hello friend infp, I identify a lot with all t...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISTP-T</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>I can't believe how accurate this was, it's so...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFP-T</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>We matter. I be Grace too. It be so refresh kn...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFP-T</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>Finally I know for sure that I be not a weirdo...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFP-T</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>I finally feel understood. I always give and g...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41695</th>\n",
       "      <td>ENTP-T</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>I'm such a debater I have to debate before dec...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41696</th>\n",
       "      <td>ENTP-A</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>Accurate</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697</th>\n",
       "      <td>ENTP-A</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>Debatable</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41698</th>\n",
       "      <td>ENTP-T</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>relatable</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41699</th>\n",
       "      <td>ENTP-T</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>I debate the actuality of be be a debater and ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41700 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      personality type                                         source url  \\\n",
       "0               INFP-A  https://www.16personalities.com/infp-strengths...   \n",
       "1               ISTP-T  https://www.16personalities.com/infp-strengths...   \n",
       "2               INFP-T  https://www.16personalities.com/infp-strengths...   \n",
       "3               INFP-T  https://www.16personalities.com/infp-strengths...   \n",
       "4               INFP-T  https://www.16personalities.com/infp-strengths...   \n",
       "...                ...                                                ...   \n",
       "41695           ENTP-T   https://www.16personalities.com/entp-personality   \n",
       "41696           ENTP-A   https://www.16personalities.com/entp-personality   \n",
       "41697           ENTP-A   https://www.16personalities.com/entp-personality   \n",
       "41698           ENTP-T   https://www.16personalities.com/entp-personality   \n",
       "41699           ENTP-T   https://www.16personalities.com/entp-personality   \n",
       "\n",
       "                                                 comment  is_reply  \n",
       "0      Hello friend infp, I identify a lot with all t...     False  \n",
       "1      I can't believe how accurate this was, it's so...     False  \n",
       "2      We matter. I be Grace too. It be so refresh kn...      True  \n",
       "3      Finally I know for sure that I be not a weirdo...     False  \n",
       "4      I finally feel understood. I always give and g...     False  \n",
       "...                                                  ...       ...  \n",
       "41695  I'm such a debater I have to debate before dec...     False  \n",
       "41696                                           Accurate     False  \n",
       "41697                                          Debatable      True  \n",
       "41698                                          relatable      True  \n",
       "41699  I debate the actuality of be be a debater and ...     False  \n",
       "\n",
       "[41700 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "for index, row in df.iterrows():\n",
    "    comment = str(row['comment'])\n",
    "    lemmitized_comment = \" \".join([lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in comment.split()])\n",
    "    df.loc[index, 'comment'] = lemmitized_comment\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract classification categories\n",
    "\n",
    "\n",
    "We aren't going to try and classify all 32 personality types (for now), we are just going to look at the first category (Extraversion vs Introversion). As our personality type data is structured using these handy codes, all we need to do is extract the first character from the string to do this (using `df['personality type'].str.strip().str[0]`). We will come back to this code later to try other ways of dividing our dataset.\n",
    "\n",
    "The class `LabelEncoder` is a handy tool to then convert whatever classes we have into integer numbers starting from one (that we need to have for our classifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personality type</th>\n",
       "      <th>source url</th>\n",
       "      <th>comment</th>\n",
       "      <th>is_reply</th>\n",
       "      <th>feat_to_classify</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFP-A</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>Hello friend infp, I identify a lot with all t...</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISTP-T</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>I can't believe how accurate this was, it's so...</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFP-T</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>We matter. I be Grace too. It be so refresh kn...</td>\n",
       "      <td>True</td>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFP-T</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>Finally I know for sure that I be not a weirdo...</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFP-T</td>\n",
       "      <td>https://www.16personalities.com/infp-strengths...</td>\n",
       "      <td>I finally feel understood. I always give and g...</td>\n",
       "      <td>False</td>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41695</th>\n",
       "      <td>ENTP-T</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>I'm such a debater I have to debate before dec...</td>\n",
       "      <td>False</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41696</th>\n",
       "      <td>ENTP-A</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>Accurate</td>\n",
       "      <td>False</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697</th>\n",
       "      <td>ENTP-A</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>Debatable</td>\n",
       "      <td>True</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41698</th>\n",
       "      <td>ENTP-T</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>relatable</td>\n",
       "      <td>True</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41699</th>\n",
       "      <td>ENTP-T</td>\n",
       "      <td>https://www.16personalities.com/entp-personality</td>\n",
       "      <td>I debate the actuality of be be a debater and ...</td>\n",
       "      <td>False</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41700 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      personality type                                         source url  \\\n",
       "0               INFP-A  https://www.16personalities.com/infp-strengths...   \n",
       "1               ISTP-T  https://www.16personalities.com/infp-strengths...   \n",
       "2               INFP-T  https://www.16personalities.com/infp-strengths...   \n",
       "3               INFP-T  https://www.16personalities.com/infp-strengths...   \n",
       "4               INFP-T  https://www.16personalities.com/infp-strengths...   \n",
       "...                ...                                                ...   \n",
       "41695           ENTP-T   https://www.16personalities.com/entp-personality   \n",
       "41696           ENTP-A   https://www.16personalities.com/entp-personality   \n",
       "41697           ENTP-A   https://www.16personalities.com/entp-personality   \n",
       "41698           ENTP-T   https://www.16personalities.com/entp-personality   \n",
       "41699           ENTP-T   https://www.16personalities.com/entp-personality   \n",
       "\n",
       "                                                 comment  is_reply  \\\n",
       "0      Hello friend infp, I identify a lot with all t...     False   \n",
       "1      I can't believe how accurate this was, it's so...     False   \n",
       "2      We matter. I be Grace too. It be so refresh kn...      True   \n",
       "3      Finally I know for sure that I be not a weirdo...     False   \n",
       "4      I finally feel understood. I always give and g...     False   \n",
       "...                                                  ...       ...   \n",
       "41695  I'm such a debater I have to debate before dec...     False   \n",
       "41696                                           Accurate     False   \n",
       "41697                                          Debatable      True   \n",
       "41698                                          relatable      True   \n",
       "41699  I debate the actuality of be be a debater and ...     False   \n",
       "\n",
       "      feat_to_classify  class_label  \n",
       "0                    I            1  \n",
       "1                    I            1  \n",
       "2                    I            1  \n",
       "3                    I            1  \n",
       "4                    I            1  \n",
       "...                ...          ...  \n",
       "41695                E            0  \n",
       "41696                E            0  \n",
       "41697                E            0  \n",
       "41698                E            0  \n",
       "41699                E            0  \n",
       "\n",
       "[41700 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df['feat_to_classify'] = df['personality type'].str.strip().str[0]\n",
    "df['class_label'] = le.fit_transform(df['feat_to_classify'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets extract our comments, class labels and the associated names of our classes into Python lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = df[\"comment\"].values.tolist()\n",
    "class_labels = df[\"class_label\"].values.tolist()\n",
    "class_names = list(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words features\n",
    "\n",
    "Lets fit our bag of words to our entire dataset first so that the our bag of words feature vectors are the same length in both our test and train sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our bag of words for the whole dataset is a matrix of the shape and size (41700, 23173)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stopwords.words('english'), ngram_range=(1,1))\n",
    "bag_of_words = vectorizer.fit_transform(comments)\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "print(f'Our bag of words for the whole dataset is a matrix of the shape and size {bag_of_words.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split dataset\n",
    "\n",
    "Now lets split our dataset into **train** and **test** sets. The training set will be used to optimise our classifier on the data. The test set is used to evaluate our classifier after training. \n",
    "\n",
    "Here `X_train` and `X_test` are our comments. `y_train` and `y_test` are our class labels corresponding to each comment. Our classify will take the bag of words representations of our comments data as input and try to give the most accurate predictions of classes. \n",
    "\n",
    "It is very important that we **never evaluate a classifer on our training data**, and that **we never train on our test data**. When we do training we repeatedly optimise on that data. Therefore the accuracy in training won't give us an accurate idea of how well our classifer is performing. We can only determine a realsitic idea of accuracy on **unseen data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(comments, class_labels, test_size=0.3, random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets redo the bag of words on the test and train with .transform() instead of .fit_transform() to ensure we use the complete vocabulary for both the test and train sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 381027 stored elements and shape (29190, 23173)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow = vectorizer.transform(X_train)\n",
    "X_train_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate topics\n",
    "\n",
    "In this cell we will set the number of topics that we want to use for topic modelling, define our topic modelling algorithm and fit the topic modelling algorithm to our training data.\n",
    "\n",
    "*Note that we do **not** want to fit the topic modeling algorithm to the full dataset, which includes training + testing data! This would prevent us from using the testing data to get as accurate an understanding of how well our approach is likely to work on new, **unseen** data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 10\n",
    "pd.options.display.max_columns=num_topics #Make sure we display them all\n",
    "labels = ['topic{}'.format(i) for i in range(num_topics)]\n",
    "lda = LatentDirichletAllocation(n_components=num_topics,random_state=123, learning_method='batch')\n",
    "lda_train_topics = lda.fit_transform(X_train_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at our topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pumpkin</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100002</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100014</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.099984</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medication</th>\n",
       "      <td>0.100014</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.302544</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100007</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.999822</td>\n",
       "      <td>0.997608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extroverttttt</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intimidate</th>\n",
       "      <td>6.361967</td>\n",
       "      <td>0.100003</td>\n",
       "      <td>5.630793</td>\n",
       "      <td>0.100012</td>\n",
       "      <td>4.270065</td>\n",
       "      <td>8.725225</td>\n",
       "      <td>0.100012</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>3.403943</td>\n",
       "      <td>11.207974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>implement</th>\n",
       "      <td>3.136740</td>\n",
       "      <td>0.100001</td>\n",
       "      <td>14.924794</td>\n",
       "      <td>0.100005</td>\n",
       "      <td>0.111220</td>\n",
       "      <td>0.100098</td>\n",
       "      <td>0.227114</td>\n",
       "      <td>0.100004</td>\n",
       "      <td>0.100007</td>\n",
       "      <td>0.100016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fdsngl</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nahhhhh</th>\n",
       "      <td>0.100007</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100012</td>\n",
       "      <td>1.099981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propensities</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100040</td>\n",
       "      <td>1.099948</td>\n",
       "      <td>0.100012</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celebrities</th>\n",
       "      <td>2.474412</td>\n",
       "      <td>1.547222</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.099952</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>0.100007</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.278364</td>\n",
       "      <td>0.100016</td>\n",
       "      <td>0.100023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manga</th>\n",
       "      <td>2.547513</td>\n",
       "      <td>1.099981</td>\n",
       "      <td>0.100002</td>\n",
       "      <td>0.100007</td>\n",
       "      <td>0.100029</td>\n",
       "      <td>2.823848</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>0.962545</td>\n",
       "      <td>3.066064</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adam</th>\n",
       "      <td>0.100006</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100002</td>\n",
       "      <td>1.099993</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100010</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.099989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linework</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100077</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.099923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>legal</th>\n",
       "      <td>6.028196</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.476731</td>\n",
       "      <td>0.794940</td>\n",
       "      <td>0.100057</td>\n",
       "      <td>0.100018</td>\n",
       "      <td>0.100022</td>\n",
       "      <td>0.100001</td>\n",
       "      <td>0.100033</td>\n",
       "      <td>0.100003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>factly</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100027</td>\n",
       "      <td>0.100004</td>\n",
       "      <td>0.100013</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.099956</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>li</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100014</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.099986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logic</th>\n",
       "      <td>12.810406</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>153.631587</td>\n",
       "      <td>4.067033</td>\n",
       "      <td>4.216990</td>\n",
       "      <td>0.340465</td>\n",
       "      <td>0.986242</td>\n",
       "      <td>0.100011</td>\n",
       "      <td>1.647235</td>\n",
       "      <td>0.100024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grinning</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.099973</td>\n",
       "      <td>0.100016</td>\n",
       "      <td>0.100010</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interactive</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100017</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.099995</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.099987</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.100002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>challanges</th>\n",
       "      <td>2.099944</td>\n",
       "      <td>0.100036</td>\n",
       "      <td>0.100008</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100012</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  topic0    topic1      topic2    topic3    topic4    topic5  \\\n",
       "pumpkin         0.100000  0.100000    0.100000  0.100002  0.100000  0.100000   \n",
       "medication      0.100014  0.100000    0.302544  0.100000  0.100006  0.100000   \n",
       "extroverttttt   0.100000  0.100000    0.100000  0.100000  0.100000  0.100000   \n",
       "intimidate      6.361967  0.100003    5.630793  0.100012  4.270065  8.725225   \n",
       "implement       3.136740  0.100001   14.924794  0.100005  0.111220  0.100098   \n",
       "fdsngl          0.100000  0.100000    0.100000  0.100000  1.100000  0.100000   \n",
       "nahhhhh         0.100007  0.100000    0.100000  0.100000  0.100000  0.100000   \n",
       "propensities    0.100000  0.100000    0.100040  1.099948  0.100012  0.100000   \n",
       "celebrities     2.474412  1.547222    0.100000  2.099952  0.100006  0.100007   \n",
       "manga           2.547513  1.099981    0.100002  0.100007  0.100029  2.823848   \n",
       "adam            0.100006  0.100000    0.100002  1.099993  0.100000  0.100000   \n",
       "linework        0.100000  0.100000    0.100000  0.100000  0.100077  0.100000   \n",
       "legal           6.028196  0.100000    2.476731  0.794940  0.100057  0.100018   \n",
       "factly          0.100000  0.100027    0.100004  0.100013  0.100000  0.100000   \n",
       "li              0.100000  0.100000    0.100014  0.100000  0.100000  0.100000   \n",
       "logic          12.810406  0.100006  153.631587  4.067033  4.216990  0.340465   \n",
       "el              0.100000  0.100000    0.100000  0.100000  0.100000  0.100000   \n",
       "grinning        0.100000  0.100000    0.100000  1.099973  0.100016  0.100010   \n",
       "interactive     0.100000  0.100000    0.100017  0.100000  1.099995  0.100000   \n",
       "challanges      2.099944  0.100036    0.100008  0.100000  0.100012  0.100000   \n",
       "\n",
       "                 topic6    topic7    topic8     topic9  \n",
       "pumpkin        0.100014  0.100000  2.099984   0.100000  \n",
       "medication     0.100007  0.100000  1.999822   0.997608  \n",
       "extroverttttt  0.100000  0.100000  0.100000   0.100000  \n",
       "intimidate     0.100012  0.100006  3.403943  11.207974  \n",
       "implement      0.227114  0.100004  0.100007   0.100016  \n",
       "fdsngl         0.100000  0.100000  0.100000   0.100000  \n",
       "nahhhhh        0.100000  0.100000  0.100012   1.099981  \n",
       "propensities   0.100000  0.100000  0.100000   0.100000  \n",
       "celebrities    0.100000  1.278364  0.100016   0.100023  \n",
       "manga          0.100011  0.962545  3.066064   0.100000  \n",
       "adam           0.100000  0.100010  0.100000   2.099989  \n",
       "linework       0.100000  0.100000  0.100000   1.099923  \n",
       "legal          0.100022  0.100001  0.100033   0.100003  \n",
       "factly         1.099956  0.100000  0.100000   0.100000  \n",
       "li             0.100000  0.100000  0.100000   1.099986  \n",
       "logic          0.986242  0.100011  1.647235   0.100024  \n",
       "el             0.100000  0.100000  0.100000   0.100000  \n",
       "grinning       0.100000  0.100000  0.100000   0.100000  \n",
       "interactive    1.099987  0.100000  0.100000   1.100002  \n",
       "challanges     0.100000  0.100000  0.100000   0.100000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_weights = pd.DataFrame(lda.components_.T, index=vocab, columns=labels)\n",
    "topic_weights.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train classifier\n",
    "\n",
    "Now lets define what kind of classifer we are using and train it on our training data. We will give our Bag our words matrix for our entire training set, and out list of classes labels that corresponds to each row in the matrix. The classifier implementation from sci-kit learn will take care of the rest for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(lda_train_topics, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare test data\n",
    "\n",
    "Now lets vectorise our test data and get our associations to our topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 163165 stored elements and shape (12510, 23173)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_bow = vectorizer.transform(X_test)\n",
    "X_test_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_test_topics = lda.transform(X_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test classifier\n",
    "\n",
    "Now we have trained our classifer we can test it. We will get the classifer to make predictions on our test dataset. We will then calucate our accuracy scores by comparing our predictions `y_pred` to our true class labels `y_test`. \n",
    "\n",
    "Sci-kit learn gives us a nice classification report, breaking it down into three scores, **precision**, **recall** and **f1-score**. **Precision** tells us of **True Positives / True Positive + False Positives** (how many retrieved elements are relevant). **Recall** tells us of **True Positives / True Positive + False Negatives** (how many relevant items are retrieved). The **F1-Score** tells us an average (the harmonic mean) of these two scores.\n",
    "\n",
    "<img src=\"../media/precision-recall.png\" alt=\"precision recall diagram\" width=\"500\"/>\n",
    "<img src=\"../media/f1-score.png\" alt=\"F1 score formula\" width=\"500\"/>\n",
    "\n",
    "There is not perfect way to measure accuracy. In some cases, you will be happy with a high recall and low precision if you want to find all possible results, and can use a human expert to check to result (i.e. if you were looking for possible cases of cancer). In other cases you may want high precision but are less bothered about having a high recall (i.e. if were deciding one of many possible stocks to buy that you want to make a profit from).\n",
    "\n",
    "Another analogy would be if you were fishing, recall is **how big your net is** and precision is **how effective your net is at catching fish (and not other things in the sea)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(lda_test_topics)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=class_names)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "**Task 1** Run this notebook and the classification just with Bag of Words features. Which one works better? \n",
    "\n",
    "**Task 2** Try splitting this dataset using some of the other personality distinctions, you can do this by modifying [the cell where we extract the categories we are using for classificaiton](#extract-classification-categories). Try some of the other individual binary distinctions, then see if you can train a classifer on all 16 of the original Myers-Briggs personality types. Can you then do all 32 different categories available to us in the dataset?\n",
    "\n",
    "**Task 3** You may have noticed that we often get perfomance on one of more of the classes we have when we have a large imbalance between the numbers for each class (listed as `support` in our classification report). Try [changing the type of classifier](#train-classifier) used to another one of the [many available classifiers](https://scikit-learn.org/stable/supervised_learning.html) in sci-kit learn.\n",
    "\n",
    "**Task 4** Does [changing the number of topics](#calculate-topics) impact classification accuracy?\n",
    "\n",
    "**Task 5** Can you change the code to use TF-IDF features and LSA instead of BoW and LDA?\n",
    "\n",
    "**Task 6** Discuss with a someone on your table:\n",
    "- What are the potential uses of a text classifier trained on personality characteristics?\n",
    "- What are the ethical concerns of using this dataset?\n",
    "- What are the potential misuses of this dataset? \n",
    "- What are the biases present in this dataset?\n",
    "\n",
    "### Bonus tasks\n",
    "\n",
    "**Task A** Can you filter the dataset in some way. For instance you could filter out comments that are replies (using `is_reply` in the dataset) or filter out comments that are below (or above) a certain length. The `source_url` may also be something that you use to filter out particular comments. \n",
    "\n",
    "**Task B** Does using a stemmer instead of a lemmatizer effect the classification scores? What happens if you don't do any pre-processing to the text?\n",
    "\n",
    "**Task C** Can you add any stop words that are specific to this dataset? Does that improve classification results?\n",
    "\n",
    "**Task D** Can you save the results from classification (and any other important meta-data) to a log file. This can just be an append only text file that you log the results of each experiment to, to make comparisons with later. \n",
    "\n",
    "**Task E** If you are doing lots of experiments using the same preprocessing to the text (stemming / lemmatisation), can you perform this and then save that dataset to a separate `.tsv` file. Which then only have to pre-process once, and then can then load directly into your code each time you runa  new experiment?\n",
    "\n",
    "**Task F** Look for other classification datasets on [kaggle](). Can you adapt this notebook to work with a different classification dataset. You may want to make a copy of this notebook before making changes to a new dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
