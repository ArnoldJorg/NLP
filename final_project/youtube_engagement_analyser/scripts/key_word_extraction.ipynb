{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from scikit-learn) (2.2.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.2-cp311-cp311-macosx_10_13_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.6.1-cp311-cp311-macosx_10_9_x86_64.whl (12.1 MB)\n",
      "Downloading scipy-1.15.2-cp311-cp311-macosx_10_13_x86_64.whl (38.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.7/38.7 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0mm[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing Video Data:\n",
      "\n",
      " Processing Description & Tags Data:\n",
      "\n",
      " Title Keywords: ['12' 'advice' 'best' 'doing' 'future' 'jordan' 'life' 'matter' 'meaning'\n",
      " 'monster' 'motivation' 'motivational' 'negative' 'peterson' 'reminder'\n",
      " 'rules' 'screwed' 'speeches' 'treat' 'worth']\n",
      "\n",
      " Description Keywords: ['30' 'adventure' 'advice' 'amzn' 'books' 'chriswillx' 'contact' 'content'\n",
      " 'discount' 'don' 'educational' 'free' 'going' 'idea' 'instagram' 'jordan'\n",
      " 'jordanbpeterson' 'jordanpetersonvideos' 'just' 'know' 'life' 'like'\n",
      " 'modernwisdom' 'motivational' 'mulliganbrothers' 'order' 'owner'\n",
      " 'patreon' 'people' 'peterson' 'purpose' 'really' 'rules' 'say' 'share'\n",
      " 'speaker' 'tell' 'thing' 'things' 'think' 'try' 'twitter' 'use' 'used'\n",
      " 'user' 've' 'videos' 'want' 'way' 'wordtothewise']\n",
      "\n",
      " Tags Keywords: ['2018' 'advice' 'best' 'chris' 'interview' 'jordan' 'life' 'modern'\n",
      " 'motivation' 'motivational' 'peterson' 'podcast' 'powerful' 'productive'\n",
      " 'rules' 'self' 'speech' 'success' 'williamson' 'wisdom']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "custom_stop_words = list(ENGLISH_STOP_WORDS) + [\"http\", \"https\", \"com\", \"www\", \"youtu\", \"youtube\", \"bit\", \"ly\", \"watch\", \"video\"]\n",
    "\n",
    "\n",
    "# Load data\n",
    "youtube_data = pd.read_csv(\"../data/youtube_data.csv\")  # Title, Views, Likes, CategoryId, Published Date, Channel Name, Id\n",
    "df_description_tags = pd.read_csv(\"../data/youtube_description_and_tags.csv\")  # Tags, Description\n",
    "\n",
    "\n",
    "columns_with_stop_words = [\"Description\"]  \n",
    "columns_without_stop_words = [\"Title\", \"Tags\"]  \n",
    "\n",
    "keyword_results = {}  \n",
    "\n",
    "def extract_tfidf(df, max_features=20):\n",
    "    \"\"\"Extracts TF-IDF keywords for each column in the dataframe.\"\"\"\n",
    "    \n",
    "\n",
    "    for col in df.columns:\n",
    "        if col not in columns_with_stop_words + columns_without_stop_words:\n",
    "            continue  # Skip irrelevant columns\n",
    "\n",
    "        text_data = df[col].dropna().tolist()  # Remove NaNs\n",
    "\n",
    "        if not text_data:  # If column is empty, skip it\n",
    "            keyword_results[col] = []\n",
    "            continue\n",
    "\n",
    "        stop_words = custom_stop_words if col in columns_with_stop_words else None\n",
    "\n",
    "\n",
    "        max_feats = 50 if col in columns_with_stop_words else 20\n",
    "\n",
    "\n",
    "        vectorizer = TfidfVectorizer(stop_words=custom_stop_words, max_features=max_feats)\n",
    "        tfidf_matrix = vectorizer.fit_transform(text_data)\n",
    "        keywords = vectorizer.get_feature_names_out()\n",
    "\n",
    "        keyword_results[col] = keywords  # Store keywords for this column\n",
    "\n",
    "    return keyword_results  \n",
    "\n",
    "print(\"\\n Processing Video Data:\")\n",
    "video_keywords = extract_tfidf(youtube_data)\n",
    "\n",
    "print(\"\\n Processing Description & Tags Data:\")\n",
    "description_tags_keywords = extract_tfidf(df_description_tags)\n",
    "\n",
    "# Print results\n",
    "print(\"\\n Title Keywords:\", video_keywords.get(\"Title\"))\n",
    "print(\"\\n Description Keywords:\", description_tags_keywords.get(\"Description\"))\n",
    "print(\"\\n Tags Keywords:\", description_tags_keywords.get(\"Tags\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### My output was initially:\n",
    "\n",
    "\n",
    " Processing Video Data:\n",
    "\n",
    " Processing Description & Tags Data:\n",
    "\n",
    " Title Keywords: ['12' '4k' 'advice' 'amazing' 'anything' 'best' 'change' 'choice'\n",
    " 'control' 'discipline' 'doing' 'jordan' 'life' 'motivation' 'peterson'\n",
    " 'to' 'worth' 'you' 'your' 'yourself']\n",
    "\n",
    " Description Keywords: ['30' 'advice' 'amzn' 'bit' 'chriswillx' 'com' 'contact' 'content' 'don'\n",
    " 'educational' 'free' 'http' 'https' 'idea' 'instagram' 'jordan'\n",
    " 'jordanbpeterson' 'just' 'know' 'life' 'like' 'ly' 'modernwisdom'\n",
    " 'motivational' 'order' 'owner' 'patreon' 'people' 'peterson' 'purpose'\n",
    " 'really' 'rules' 'say' 'tell' 'thing' 'things' 'think' 'try' 'twitter'\n",
    " 'used' 've' 'video' 'videos' 'want' 'watch' 'way' 'wordtothewise' 'www'\n",
    " 'youtu' 'youtube']\n",
    "\n",
    " Tags Keywords: ['2018' 'advice' 'be' 'best' 'chris' 'for' 'jordan' 'life' 'modern'\n",
    " 'motivation' 'motivational' 'peterson' 'podcast' 'powerful' 'speech' 'to'\n",
    " 'video' 'williamson' 'wisdom' 'your']\n",
    "\n",
    "### ----> So I added custom stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Sentiment analysis will not be needed for comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': array(['12', 'advice', 'best', 'doing', 'future', 'jordan', 'life',\n",
      "       'matter', 'meaning', 'monster', 'motivation', 'motivational',\n",
      "       'negative', 'peterson', 'reminder', 'rules', 'screwed', 'speeches',\n",
      "       'treat', 'worth'], dtype=object), 'Tags': array(['2018', 'advice', 'best', 'chris', 'interview', 'jordan', 'life',\n",
      "       'modern', 'motivation', 'motivational', 'peterson', 'podcast',\n",
      "       'powerful', 'productive', 'rules', 'self', 'speech', 'success',\n",
      "       'williamson', 'wisdom'], dtype=object), 'Description': array(['30', 'adventure', 'advice', 'amzn', 'books', 'chriswillx',\n",
      "       'contact', 'content', 'discount', 'don', 'educational', 'free',\n",
      "       'going', 'idea', 'instagram', 'jordan', 'jordanbpeterson',\n",
      "       'jordanpetersonvideos', 'just', 'know', 'life', 'like',\n",
      "       'modernwisdom', 'motivational', 'mulliganbrothers', 'order',\n",
      "       'owner', 'patreon', 'people', 'peterson', 'purpose', 'really',\n",
      "       'rules', 'say', 'share', 'speaker', 'tell', 'thing', 'things',\n",
      "       'think', 'try', 'twitter', 'use', 'used', 'user', 've', 'videos',\n",
      "       'want', 'way', 'wordtothewise'], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "print(keyword_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_df = pd.DataFrame.from_dict(keyword_results, orient='index').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Title          Tags           Description\n",
      "0             12          2018                    30\n",
      "1         advice        advice             adventure\n",
      "2           best          best                advice\n",
      "3          doing         chris                  amzn\n",
      "4         future     interview                 books\n",
      "5         jordan        jordan            chriswillx\n",
      "6           life          life               contact\n",
      "7         matter        modern               content\n",
      "8        meaning    motivation              discount\n",
      "9        monster  motivational                   don\n",
      "10    motivation      peterson           educational\n",
      "11  motivational       podcast                  free\n",
      "12      negative      powerful                 going\n",
      "13      peterson    productive                  idea\n",
      "14      reminder         rules             instagram\n",
      "15         rules          self                jordan\n",
      "16       screwed        speech       jordanbpeterson\n",
      "17      speeches       success  jordanpetersonvideos\n",
      "18         treat    williamson                  just\n",
      "19         worth        wisdom                  know\n",
      "20          None          None                  life\n",
      "21          None          None                  like\n",
      "22          None          None          modernwisdom\n",
      "23          None          None          motivational\n",
      "24          None          None      mulliganbrothers\n",
      "25          None          None                 order\n",
      "26          None          None                 owner\n",
      "27          None          None               patreon\n",
      "28          None          None                people\n",
      "29          None          None              peterson\n",
      "30          None          None               purpose\n",
      "31          None          None                really\n",
      "32          None          None                 rules\n",
      "33          None          None                   say\n",
      "34          None          None                 share\n",
      "35          None          None               speaker\n",
      "36          None          None                  tell\n",
      "37          None          None                 thing\n",
      "38          None          None                things\n",
      "39          None          None                 think\n",
      "40          None          None                   try\n",
      "41          None          None               twitter\n",
      "42          None          None                   use\n",
      "43          None          None                  used\n",
      "44          None          None                  user\n",
      "45          None          None                    ve\n",
      "46          None          None                videos\n",
      "47          None          None                  want\n",
      "48          None          None                   way\n",
      "49          None          None         wordtothewise\n"
     ]
    }
   ],
   "source": [
    "print(keyword_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Title          Tags           Description\n",
      "0             12          2018                    30\n",
      "1         advice        advice             adventure\n",
      "2           best          best                advice\n",
      "3          doing         chris                  amzn\n",
      "4         future     interview                 books\n",
      "5         jordan        jordan            chriswillx\n",
      "6           life          life               contact\n",
      "7         matter        modern               content\n",
      "8        meaning    motivation              discount\n",
      "9        monster  motivational                   don\n",
      "10    motivation      peterson           educational\n",
      "11  motivational       podcast                  free\n",
      "12      negative      powerful                 going\n",
      "13      peterson    productive                  idea\n",
      "14      reminder         rules             instagram\n",
      "15         rules          self                jordan\n",
      "16       screwed        speech       jordanbpeterson\n",
      "17      speeches       success  jordanpetersonvideos\n",
      "18         treat    williamson                  just\n",
      "19         worth        wisdom                  know\n",
      "20          None          None                  life\n",
      "21          None          None                  like\n",
      "22          None          None          modernwisdom\n",
      "23          None          None          motivational\n",
      "24          None          None      mulliganbrothers\n",
      "25          None          None                 order\n",
      "26          None          None                 owner\n",
      "27          None          None               patreon\n",
      "28          None          None                people\n",
      "29          None          None              peterson\n",
      "30          None          None               purpose\n",
      "31          None          None                really\n",
      "32          None          None                 rules\n",
      "33          None          None                   say\n",
      "34          None          None                 share\n",
      "35          None          None               speaker\n",
      "36          None          None                  tell\n",
      "37          None          None                 thing\n",
      "38          None          None                things\n",
      "39          None          None                 think\n",
      "40          None          None                   try\n",
      "41          None          None               twitter\n",
      "42          None          None                   use\n",
      "43          None          None                  used\n",
      "44          None          None                  user\n",
      "45          None          None                    ve\n",
      "46          None          None                videos\n",
      "47          None          None                  want\n",
      "48          None          None                   way\n",
      "49          None          None         wordtothewise\n"
     ]
    }
   ],
   "source": [
    "keyword_df_filled = keyword_df.fillna('N/A')\n",
    "\n",
    "print(keyword_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_df.to_csv(\"../data/keywords_tags_titles_descriptions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
