{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.30.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_10_12_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from ipywidgets) (9.0.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from requests->transformers) (2025.1.31)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m71.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m36m0:00:05\u001b[0mm\n",
      "\u001b[?25hDownloading torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 MB\u001b[0m \u001b[31m130.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:28\u001b[0m\n",
      "\u001b[?25hDownloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m134.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.30.1-py3-none-any.whl (481 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.2/481.2 kB\u001b[0m \u001b[31m122.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m89.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m85.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 kB\u001b[0m \u001b[31m66.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp311-cp311-macosx_10_9_x86_64.whl (184 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.6/184.6 kB\u001b[0m \u001b[31m95.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-macosx_10_12_x86_64.whl (436 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.9/436.9 kB\u001b[0m \u001b[31m103.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-macosx_10_12_x86_64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m240.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m323.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m419.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m385.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m248.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-macosx_10_9_universal2.whl (14 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m225.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, widgetsnbextension, sympy, safetensors, pyyaml, networkx, MarkupSafe, jupyterlab-widgets, fsspec, filelock, jinja2, huggingface-hub, torch, tokenizers, ipywidgets, transformers\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.3.2 huggingface-hub-0.30.1 ipywidgets-8.1.5 jinja2-3.1.6 jupyterlab-widgets-3.0.13 mpmath-1.3.0 networkx-3.4.2 pyyaml-6.0.2 safetensors-0.5.3 sympy-1.13.3 tokenizers-0.21.1 torch-2.2.2 transformers-4.50.3 widgetsnbextension-4.0.13\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers torch ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline, set_seed, AutoModelForCausalLM, AutoTokenizer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cee9266df2b42f5a9a7fa32274a5c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "keywords_df = pd.read_csv(\"../data/keywords_tags_titles_descriptions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Title          Tags           Description\n",
      "0             12          2018                    30\n",
      "1         advice        advice             adventure\n",
      "2           best          best                advice\n",
      "3          doing         chris                  amzn\n",
      "4         future     interview                 books\n",
      "5         jordan        jordan            chriswillx\n",
      "6           life          life               contact\n",
      "7         matter        modern               content\n",
      "8        meaning    motivation              discount\n",
      "9        monster  motivational                   don\n",
      "10    motivation      peterson           educational\n",
      "11  motivational       podcast                  free\n",
      "12      negative      powerful                 going\n",
      "13      peterson    productive                  idea\n",
      "14      reminder         rules             instagram\n",
      "15         rules          self                jordan\n",
      "16       screwed        speech       jordanbpeterson\n",
      "17      speeches       success  jordanpetersonvideos\n",
      "18         treat    williamson                  just\n",
      "19         worth        wisdom                  know\n",
      "20           NaN           NaN                  life\n",
      "21           NaN           NaN                  like\n",
      "22           NaN           NaN          modernwisdom\n",
      "23           NaN           NaN          motivational\n",
      "24           NaN           NaN      mulliganbrothers\n",
      "25           NaN           NaN                 order\n",
      "26           NaN           NaN                 owner\n",
      "27           NaN           NaN               patreon\n",
      "28           NaN           NaN                people\n",
      "29           NaN           NaN              peterson\n",
      "30           NaN           NaN               purpose\n",
      "31           NaN           NaN                really\n",
      "32           NaN           NaN                 rules\n",
      "33           NaN           NaN                   say\n",
      "34           NaN           NaN                 share\n",
      "35           NaN           NaN               speaker\n",
      "36           NaN           NaN                  tell\n",
      "37           NaN           NaN                 thing\n",
      "38           NaN           NaN                things\n",
      "39           NaN           NaN                 think\n",
      "40           NaN           NaN                   try\n",
      "41           NaN           NaN               twitter\n",
      "42           NaN           NaN                   use\n",
      "43           NaN           NaN                  used\n",
      "44           NaN           NaN                  user\n",
      "45           NaN           NaN                    ve\n",
      "46           NaN           NaN                videos\n",
      "47           NaN           NaN                  want\n",
      "48           NaN           NaN                   way\n",
      "49           NaN           NaN         wordtothewise\n"
     ]
    }
   ],
   "source": [
    "print(keywords_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['the', 'a', 'and', 'is', 'in', 'to', 'for', 'on', 'of', 'with', 'as', 'an']\n",
    "keyword_df_clean = keywords_df[~keywords_df.isin(stop_words)].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting markovify\n",
      "  Downloading markovify-0.9.4.tar.gz (27 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting unidecode (from markovify)\n",
      "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: markovify\n",
      "  Building wheel for markovify (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for markovify: filename=markovify-0.9.4-py3-none-any.whl size=18695 sha256=a5e80f670eb77090af11c8d759ec7374f42b66dea58142d32ed48c9b0cbcc5a3\n",
      "  Stored in directory: /Users/arnoldm./Library/Caches/pip/wheels/9c/20/eb/1a3fb93f3132f2f9683e4efd834800f80c53aeddf50e84ae80\n",
      "Successfully built markovify\n",
      "Installing collected packages: unidecode, markovify\n",
      "Successfully installed markovify-0.9.4 unidecode-1.3.8\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('___BEGIN__',)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m text_data = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(youtube_data[\u001b[33m\"\u001b[39m\u001b[33mTitle\u001b[39m\u001b[33m\"\u001b[39m].dropna().astype(\u001b[38;5;28mstr\u001b[39m))\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Train the Markov model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m markov_model = \u001b[43mmarkovify\u001b[49m\u001b[43m.\u001b[49m\u001b[43mText\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use 1 instead of 2\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Generate a random title\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(markov_model.make_sentence())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/NLP/venv2/lib/python3.11/site-packages/markovify/text.py:65\u001b[39m, in \u001b[36mText.__init__\u001b[39m\u001b[34m(self, input_text, state_size, chain, parsed_sentences, retain_original, well_formed, reject_reg)\u001b[39m\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# Rejoined text lets us assess the novelty of generated sentences\u001b[39;00m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28mself\u001b[39m.rejoined_text = \u001b[38;5;28mself\u001b[39m.sentence_join(\n\u001b[32m     63\u001b[39m         \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m.word_join, \u001b[38;5;28mself\u001b[39m.parsed_sentences)\n\u001b[32m     64\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28mself\u001b[39m.chain = chain \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mChain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparsed_sentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chain:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/NLP/venv2/lib/python3.11/site-packages/markovify/chain.py:53\u001b[39m, in \u001b[36mChain.__init__\u001b[39m\u001b[34m(self, corpus, state_size, model)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28mself\u001b[39m.compiled = (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.model) > \u001b[32m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m     50\u001b[39m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m.model[\u001b[38;5;28mtuple\u001b[39m([BEGIN] * state_size)]) == \u001b[38;5;28mlist\u001b[39m\n\u001b[32m     51\u001b[39m )\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compiled:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecompute_begin_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/NLP/venv2/lib/python3.11/site-packages/markovify/chain.py:102\u001b[39m, in \u001b[36mChain.precompute_begin_state\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[33;03mCaches the summation calculation and available choices for BEGIN * state_size.\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[33;03mSignificantly speeds up chain generation on large corpora. Thanks, @schollz!\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    101\u001b[39m begin_state = \u001b[38;5;28mtuple\u001b[39m([BEGIN] * \u001b[38;5;28mself\u001b[39m.state_size)\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m choices, cumdist = compile_next(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbegin_state\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m    103\u001b[39m \u001b[38;5;28mself\u001b[39m.begin_cumdist = cumdist\n\u001b[32m    104\u001b[39m \u001b[38;5;28mself\u001b[39m.begin_choices = choices\n",
      "\u001b[31mKeyError\u001b[39m: ('___BEGIN__',)"
     ]
    }
   ],
   "source": [
    "import markovify\n",
    "import pandas as pd\n",
    "\n",
    "# Load your YouTube data\n",
    "youtube_data = pd.read_csv(\"../data/youtube_data.csv\")  # Ensure it has a 'Title' column\n",
    "\n",
    "# Combine all titles into one string\n",
    "text_data = \"\\n\".join(youtube_data[\"Title\"].dropna().astype(str))\n",
    "\n",
    "# Train the Markov model\n",
    "markov_model = markovify.Text(text_data, state_size=1)  # Use 1 instead of 2\n",
    "\n",
    "# Generate a random title\n",
    "print(markov_model.make_sentence())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the data set is too small for markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jordan Peterson - How To Destroy Your Negative Beliefs (4K)', 'Jordan Peterson - 7 Harsh Truths To Take Control Of Your Life', 'DISCIPLINE YOURSELF -  Best Motivational Speeches by Jordan Peterson', \"Jordan Peterson's Life Advice Will Change Your Future (MUST WATCH)\", 'The Choice We All Have , But Only a Few Apply It | Jordan Peterson', 'FIND MEANING IN YOUR LIFE - JORDAN PETERSON [AMAZING]', '\"You Should Be A Monster\" | Jordan Peterson Motivation', \"You're Screwed No Matter What You Do | Jordan Peterson\", 'A Reminder To Treat Yourself Better | Jordan Peterson Motivation | 12 Rules For Life', 'Anything Worth Doing Is Worth Doing Badly | Jordan Peterson | Best Life Advice']\n"
     ]
    }
   ],
   "source": [
    "titles = youtube_data[\"Title\"].tolist()\n",
    "print(titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worth Doing Badly | Jordan Peterson | Jordan\n",
      "Should Be A Monster\" | Jordan Peterson's Life\n",
      "7 Harsh Truths To Take Control Of Your\n",
      "Rules For Life Advice Will Change Your Life\n",
      "Worth Doing Is Worth Doing Is Worth Doing\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Step 1: Build Markov Chain\n",
    "def build_markov_chain(titles):\n",
    "    markov_chain = defaultdict(list)\n",
    "    \n",
    "    for title in titles:\n",
    "        words = title.split()\n",
    "        for i in range(len(words) - 1):\n",
    "            markov_chain[words[i]].append(words[i + 1])\n",
    "    \n",
    "    return markov_chain\n",
    "\n",
    "# Step 2: Generate New Titles\n",
    "def generate_title(chain, length=8):\n",
    "    word = random.choice(list(chain.keys()))  # Start with a random word\n",
    "    title = [word]\n",
    "    \n",
    "    for _ in range(length - 1):\n",
    "        if word in chain:\n",
    "            word = random.choice(chain[word])\n",
    "            title.append(word)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return \" \".join(title)\n",
    "\n",
    "# Build chain\n",
    "markov_chain = build_markov_chain(titles)\n",
    "\n",
    "# Generate new titles\n",
    "for _ in range(5):\n",
    "    print(generate_title(markov_chain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to generate a text file with the markov chains keywords!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To Treat Yourself Better | 12 Rules For\n",
      "Should Be A Monster\" | 12 Rules For\n",
      "Monster\" | 12 Rules For Life Advice Will\n",
      "Only a Few Apply It | 12 Rules\n",
      "Better | 12 Rules For Life Advice Will\n"
     ]
    }
   ],
   "source": [
    "# Example list of keywords (this would be from your dataset or a predefined list)\n",
    "keywords = keyword_df_clean[\"Title\"].tolist()\n",
    "\n",
    "# Step 3: Adjust the Title Generation to Include Keywords\n",
    "def generate_title_with_keywords(chain, keywords, length=8, max_attempts=100):\n",
    "    attempts = 0\n",
    "    while attempts < max_attempts:\n",
    "        title = generate_title(chain, length)\n",
    "        if any(keyword in title for keyword in keywords):\n",
    "            return title\n",
    "        attempts += 1\n",
    "    return \"No valid title found\"\n",
    "\n",
    "# Generate new titles that include the keywords\n",
    "with open(\"generated_titles.txt\", \"w\") as f:\n",
    "    for _ in range(5):\n",
    "        generated_title = generate_title_with_keywords(markov_chain, keywords)\n",
    "        f.write(generated_title + \"\\n\")  # Write each title on a new line\n",
    "\n",
    "        print(generate_title_with_keywords(markov_chain, keywords))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the generated file and splitting it into a list of different lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Be A Monster\" | Jordan Peterson | 12', '12 Rules For Life Advice Will Change Your', 'But Only a Few Apply It | 12', 'Apply It | 12 Rules For Life Advice', 'You Do | 12 Rules For Life Advice']\n"
     ]
    }
   ],
   "source": [
    "# Open the txt file and read its lines\n",
    "with open('generated_titles.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "lines = [line.strip() for line in lines]\n",
    "\n",
    "print(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to complete the sentence using GPT2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnoldm./NLP/venv2/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Be A Monster\" | Jordan Peterson | 12\n",
      "Output: Be A Monster\" | Jordan Peterson | 12/10/2014\n",
      "\n",
      "\"I'm a Monster,\" Peterson said. \"I've been a monster for a long time. I've had a lot of success. But I'm not a big guy\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 12 Rules For Life Advice Will Change Your\n",
      "Output: 12 Rules For Life Advice Will Change Your Life\n",
      "\n",
      "The following are some of the most common questions you'll get when you're trying to figure out what to do with your life.\n",
      ". . .\n",
      " (1) What is your favorite thing\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: But Only a Few Apply It | 12\n",
      "Output: But Only a Few Apply It | 12.5\n",
      "\n",
      "The Best of the Best | 11.4\n",
      ".\n",
      ",\n",
      " (1) The Best Of The Worst | 10.9\n",
      ":\n",
      "- The best of all time | 9.\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Apply It | 12 Rules For Life Advice\n",
      "Output: Apply It | 12 Rules For Life Advice | 13 Tips For Getting A Job | 14 How To Get A Good Job In The U.S. | 15 How to Get Your Job Done | 16 How You Can Get The Best Job Ever | 17 How\n",
      "==================================================\n",
      "Input: You Do | 12 Rules For Life Advice\n",
      "Output: You Do | 12 Rules For Life Advice\n",
      "\n",
      "The following are the 12 rules for life advice for people who are struggling with depression.\n",
      ". . .\n",
      " (1) Don't be afraid to ask for help. If you're struggling, you\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "\n",
    "def complete_sentence(prompt, max_length=50):\n",
    "\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "\n",
    "    output = model.generate(input_ids, max_length=max_length, num_return_sequences=1, no_repeat_ngram_size=2, temperature=0.7)\n",
    "    \n",
    "\n",
    "    completed_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    return completed_text\n",
    "\n",
    "\n",
    "sentences = lines\n",
    "\n",
    "for sentence in sentences:\n",
    "    completed = complete_sentence(sentence)\n",
    "    print(f\"Input: {sentence}\")\n",
    "    print(f\"Output: {completed}\")\n",
    "    print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (4.50.3)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-19.0.1-cp311-cp311-macosx_12_0_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.16-cp311-cp311-macosx_10_9_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.2.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.3.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.3-cp311-cp311-macosx_10_9_x86_64.whl.metadata (69 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.16-cp311-cp311-macosx_10_9_x86_64.whl (468 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-19.0.1-cp311-cp311-macosx_12_0_x86_64.whl (32.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.1/32.1 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-macosx_10_9_x86_64.whl (31 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.5.0-cp311-cp311-macosx_10_9_x86_64.whl (54 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.2.0-cp311-cp311-macosx_10_9_x86_64.whl (29 kB)\n",
      "Downloading propcache-0.3.1-cp311-cp311-macosx_10_9_x86_64.whl (46 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m923.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.18.3-cp311-cp311-macosx_10_9_x86_64.whl (94 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.4/94.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, pyarrow, propcache, multidict, fsspec, frozenlist, dill, attrs, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.16 aiosignal-1.3.2 attrs-25.3.0 datasets-3.5.0 dill-0.3.8 frozenlist-1.5.0 fsspec-2024.12.0 multidict-6.2.0 multiprocess-0.70.16 propcache-0.3.1 pyarrow-19.0.1 xxhash-3.5.0 yarl-1.18.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"text\", data_files={\"train\": \"generated_titles.txt\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate>=0.26.0\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from accelerate>=0.26.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from accelerate>=0.26.0) (24.2)\n",
      "Requirement already satisfied: psutil in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from accelerate>=0.26.0) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from accelerate>=0.26.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from accelerate>=0.26.0) (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from accelerate>=0.26.0) (0.30.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from accelerate>=0.26.0) (0.5.3)\n",
      "Requirement already satisfied: filelock in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.12.0)\n",
      "Requirement already satisfied: requests in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from sympy->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
      "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "Successfully installed accelerate-1.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: transformers[torch]\n"
     ]
    }
   ],
   "source": [
    "!pip install 'accelerate>=0.26.0'\n",
    "!pip install transformers[torch]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
