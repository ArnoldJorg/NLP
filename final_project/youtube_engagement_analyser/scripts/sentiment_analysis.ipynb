{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using NLTK library and use VADER for the sentiment analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from nltk) (4.67.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/arnoldm./nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: requests in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from vaderSentiment) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from requests->vaderSentiment) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from requests->vaderSentiment) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from requests->vaderSentiment) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/arnoldm./NLP/venv2/lib/python3.11/site-packages (from requests->vaderSentiment) (2025.1.31)\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sentiment analysis complete. Results saved to youtube_comment_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "\n",
    "# Load comments CSV\n",
    "comment_df = pd.read_csv(\"../data/youtube_comment_data_cleaned.csv\")\n",
    "\n",
    "# Initialize Sentiment Analyzer\n",
    "sid_obj = SentimentIntensityAnalyzer()\n",
    "\n",
    "# List to store sentiment results\n",
    "sentiment_results = []\n",
    "\n",
    "def sentiment_scores():\n",
    "    \"\"\"Processes sentiment for each comment and stores results.\"\"\"\n",
    "    for _, row in comment_df.iterrows():\n",
    "        comment_text = str(row[\"Comment\"])  # Ensure text format\n",
    "        comment_id = row[\"Index\"]\n",
    "        video_id = row[\"Id\"]\n",
    "\n",
    "        # Skip empty or NaN comments\n",
    "        if comment_text.strip().lower() in [\"nan\", \"none\", \"\"]:\n",
    "            continue\n",
    "\n",
    "        # Compute sentiment scores\n",
    "        sentiment_dict = sid_obj.polarity_scores(comment_text)\n",
    "        compound_score = sentiment_dict[\"compound\"]\n",
    "\n",
    "        # Determine sentiment label\n",
    "        if compound_score >= 0.05:\n",
    "            sentiment_label = \"Positive\"\n",
    "        elif compound_score <= -0.05:\n",
    "            sentiment_label = \"Negative\"\n",
    "        else:\n",
    "            sentiment_label = \"Neutral\"\n",
    "\n",
    "        # Append result to list\n",
    "        sentiment_results.append({\n",
    "            \"Comment_ID\": comment_id,\n",
    "            \"Comment\": comment_text,\n",
    "            \"Sentiment_Score\": compound_score,\n",
    "            \"Sentiment_Label\": sentiment_label,\n",
    "            \"Video_Id\": video_id\n",
    "        })\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sentiment_scores()\n",
    "\n",
    "    sentiment_results_df = pd.DataFrame(sentiment_results)\n",
    "    sentiment_results_df.to_csv(\"../data/youtube_comment_sentiment.csv\", index=False)\n",
    "\n",
    "    print(\"✅ Sentiment analysis complete. Results saved to youtube_comment_sentiment.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: What's the average sentiment per video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video_Id\n",
      "-gYpCIbZjUQ    Positive\n",
      "4OmC6LyO5QI    Positive\n",
      "FJV7HeHT4q4    Positive\n",
      "IKot8dQc1Ps    Positive\n",
      "WEP5ubPMGDU    Positive\n",
      "dJyz6iK8VXE    Positive\n",
      "laSK7Pxh0_8    Positive\n",
      "rhjiANJVR6g    Positive\n",
      "wqEsTPaUZF0    Positive\n",
      "yaXm6UsSHBM    Positive\n",
      "Name: Sentiment_Label, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "df = pd.read_csv(\"../data/youtube_comment_sentiment.csv\")\n",
    "\n",
    "sentiment_counts = df.groupby(\"Video_Id\")[\"Sentiment_Label\"].apply(lambda x: Counter(x).most_common(1)[0][0])\n",
    "\n",
    "print(sentiment_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video_Id\n",
      "-gYpCIbZjUQ    0.075570\n",
      "4OmC6LyO5QI    0.240436\n",
      "FJV7HeHT4q4    0.187170\n",
      "IKot8dQc1Ps    0.164949\n",
      "WEP5ubPMGDU    0.264401\n",
      "dJyz6iK8VXE    0.234352\n",
      "laSK7Pxh0_8    0.245622\n",
      "rhjiANJVR6g    0.229627\n",
      "wqEsTPaUZF0    0.166475\n",
      "yaXm6UsSHBM    0.194000\n",
      "Name: Sentiment_Score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sentiment_average = df.groupby(\"Video_Id\")[\"Sentiment_Score\"].mean()\n",
    "print(sentiment_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
